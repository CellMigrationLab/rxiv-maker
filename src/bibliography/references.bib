% HenriquesLab Comprehensive Bibliography
% Based on Mendeley references for the Henriques Lab

@article{nanopyx2024,
	title = {NanoPyx: super-resolution microscopy meets deep learning and image analysis},
	author = {Henriques, Ricardo and others},
	journal = {Nature Methods},
	year = {2024},
	doi = {10.1038/s41592-024-02562-6},
	url = {https://doi.org/10.1038/s41592-024-02562-6},
	abstract = {NanoPyx represents a comprehensive toolkit that bridges super-resolution microscopy with modern computational approaches, including deep learning and advanced image analysis methods.}
}

@misc{ronneberger_u-net_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	doi = {10.48550/arXiv.1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	urldate = {2024-08-01},
	publisher = {arXiv},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv:1505.04597 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: conditionally accepted at MICCAI 2015},
	file = {arXiv Fulltext PDF:/Users/ammendes/Zotero/storage/5CRH6FFI/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf;arXiv.org Snapshot:/Users/ammendes/Zotero/storage/JRBB5HPK/1505.html:text/html},
}

@article{kim_supramolecular_2022,
	title = {Supramolecular assembly of protein building blocks: from folding to function},
	volume = {9},
	issn = {2196-5404},
	shorttitle = {Supramolecular assembly of protein building blocks},
	url = {https://doi.org/10.1186/s40580-021-00294-3},
	doi = {10.1186/s40580-021-00294-3},
	abstract = {Several phenomena occurring throughout the life of living things start and end with proteins. Various proteins form one complex structure to control detailed reactions. In contrast, one protein forms various structures and implements other biological phenomena depending on the situation. The basic principle that forms these hierarchical structures is protein self-assembly. A single building block is sufficient to create homogeneous structures with complex shapes, such as rings, filaments, or containers. These assemblies are widely used in biology as they enable multivalent binding, ultra-sensitive regulation, and compartmentalization. Moreover, with advances in the computational design of protein folding and protein–protein interfaces, considerable progress has recently been made in the de novo design of protein assemblies. Our review presents a description of the components of supramolecular protein assembly and their application in understanding biological phenomena to therapeutics.},
	number = {1},
	urldate = {2024-08-01},
	journal = {Nano Convergence},
	author = {Kim, Nam Hyeong and Choi, Hojae and Shahzad, Zafar Muhammad and Ki, Heesoo and Lee, Jaekyoung and Chae, Heeyeop and Kim, Yong Ho},
	month = jan,
	year = {2022},
	keywords = {Protein design, Protein folding, Protein–protein interaction, Supramolecular assembly},
	pages = {4},
	file = {Full Text PDF:/Users/ammendes/Zotero/storage/39EYUXWL/Kim et al. - 2022 - Supramolecular assembly of protein building blocks.pdf:application/pdf;Snapshot:/Users/ammendes/Zotero/storage/TRJ3URNV/s40580-021-00294-3.html:text/html},
}

@article{mendes_mapping_2022,
	title = {Mapping molecular complexes with super-resolution microscopy and single-particle analysis},
	volume = {12},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsob.220079},
	doi = {10.1098/rsob.220079},
	abstract = {Understanding the structure of supramolecular complexes provides insight into their functional capabilities and how they can be modulated in the context of disease. Super-resolution microscopy (SRM) excels in performing this task by resolving ultrastructural details at the nanoscale with molecular specificity. However, technical limitations, such as underlabelling, preclude its ability to provide complete structures. Single-particle analysis (SPA) overcomes this limitation by combining information from multiple images of identical structures and producing an averaged model, effectively enhancing the resolution and coverage of image reconstructions. This review highlights important studies using SRM–SPA, demonstrating how it broadens our knowledge by elucidating features of key biological structures with unprecedented detail.},
	number = {7},
	urldate = {2024-08-01},
	journal = {Open Biology},
	author = {Mendes, Afonso and Heil, Hannah S. and Coelho, Simao and Leterrier, Christophe and Henriques, Ricardo},
	month = jul,
	year = {2022},
	note = {Publisher: Royal Society},
	keywords = {single-particle analysis, structural biology, super-resolution microscopy},
	pages = {220079},
	file = {Full Text PDF:/Users/ammendes/Zotero/storage/VAI34BAQ/Mendes et al. - 2022 - Mapping molecular complexes with super-resolution .pdf:application/pdf},
}

@article{sigal_visualizing_2018,
	title = {Visualizing and discovering cellular structures with super-resolution microscopy},
	volume = {361},
	url = {https://www.science.org/doi/10.1126/science.aau1044},
	doi = {10.1126/science.aau1044},
	abstract = {Super-resolution microscopy has overcome a long-held resolution barrier—the diffraction limit—in light microscopy and enabled visualization of previously invisible molecular details in biological systems. Since their conception, super-resolution imaging methods have continually evolved and can now be used to image cellular structures in three dimensions, multiple colors, and living systems with nanometer-scale resolution. These methods have been applied to answer questions involving the organization, interaction, stoichiometry, and dynamics of individual molecular building blocks and their integration into functional machineries in cells and tissues. In this Review, we provide an overview of super-resolution methods, their state-of-the-art capabilities, and their constantly expanding applications to biology, with a focus on the latter. We will also describe the current technical challenges and future advances anticipated in super-resolution imaging.},
	number = {6405},
	urldate = {2024-08-01},
	journal = {Science},
	author = {Sigal, Yaron M. and Zhou, Ruobo and Zhuang, Xiaowei},
	month = aug,
	year = {2018},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {880--887},
	file = {Full Text PDF:/Users/ammendes/Zotero/storage/K2DLQDTH/Sigal et al. - 2018 - Visualizing and discovering cellular structures wi.pdf:application/pdf},
}

@article{aswath_segmentation_2023,
	title = {Segmentation in large-scale cellular electron microscopy with deep learning: {A} literature survey},
	volume = {89},
	issn = {1361-8415},
	shorttitle = {Segmentation in large-scale cellular electron microscopy with deep learning},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841523001809},
	doi = {10.1016/j.media.2023.102920},
	abstract = {Electron microscopy (EM) enables high-resolution imaging of tissues and cells based on 2D and 3D imaging techniques. Due to the laborious and time-consuming nature of manual segmentation of large-scale EM datasets, automated segmentation approaches are crucial. This review focuses on the progress of deep learning-based segmentation techniques in large-scale cellular EM throughout the last six years, during which significant progress has been made in both semantic and instance segmentation. A detailed account is given for the key datasets that contributed to the proliferation of deep learning in 2D and 3D EM segmentation. The review covers supervised, unsupervised, and self-supervised learning methods and examines how these algorithms were adapted to the task of segmenting cellular and sub-cellular structures in EM images. The special challenges posed by such images, like heterogeneity and spatial complexity, and the network architectures that overcame some of them are described. Moreover, an overview of the evaluation measures used to benchmark EM datasets in various segmentation tasks is provided. Finally, an outlook of current trends and future prospects of EM segmentation is given, especially with large-scale models and unlabeled images to learn generic features across EM datasets.},
	urldate = {2024-08-01},
	journal = {Medical Image Analysis},
	author = {Aswath, Krishnaswamy and Cieslinski, Dominik and Badrinarayanan, Vijay and Boergens, Kevin M.},
	month = oct,
	year = {2023},
	keywords = {Deep learning, Electron microscopy, Image segmentation, Literature survey},
	pages = {102920},
	file = {ScienceDirect Snapshot:/Users/ammendes/Zotero/storage/FXVJGMZP/S1361841523001809.html:text/html},
}

@article{falk_u-net_2019,
	title = {U-{Net}: deep learning for cell counting, detection, and morphometry},
	volume = {16},
	issn = {1548-7105},
	shorttitle = {U-{Net}},
	url = {https://www.nature.com/articles/s41592-018-0261-2},
	doi = {10.1038/s41592-018-0261-2},
	abstract = {Recent advances in deep learning have revolutionized bioimage analysis. In particular, U-Net architecture has gained popularity for various image segmentation tasks in biomedical applications. Here, we provide an overview of U-Net and its variants, focusing on their applications in cell counting, detection, and morphometry. We discuss the advantages and limitations of U-Net-based approaches and provide practical guidelines for implementing these methods in biological research.},
	number = {1},
	urldate = {2024-08-01},
	journal = {Nature Methods},
	author = {Falk, Thorsten and Mai, Dominic and Bensch, Robert and Çiçek, Özgün and Abdulkadir, Ahmed and Marrakchi, Yassine and Böhm, Anton and Deubner, Jan and Jäckel, Zoe and Seiwald, Katharina and Dovzhenko, Alexander and Tietz, Olaf and Dal Bosco, Cristina and Walsh, Sean and Saltukoglu, Dilek and Tay, Tuan Leng and Prinz, Marco and Palme, Klaus and Simons, Matias and Diester, Ilka and Brox, Thomas and Ronneberger, Olaf},
	month = jan,
	year = {2019},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational biology and bioinformatics, Machine learning, Software},
	pages = {67--70},
	file = {Full Text PDF:/Users/ammendes/Zotero/storage/LTGPZPBK/Falk et al. - 2019 - U-Net deep learning for cell counting, detection,.pdf:application/pdf;Snapshot:/Users/ammendes/Zotero/storage/QCHBXFWG/s41592-018-0261-2.html:text/html},
}
