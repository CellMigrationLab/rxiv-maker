# RXiv-Maker: An Automated Template Engine for Streamlined Scientific Publications
<!-- note that this title is not rendered in the PDF, rather the one in the YAML metadata is used -->

## Abstract
Modern scientific publishing has moved towards rapid dissemination through preprint servers, putting greater demands on researchers for preparing and quality-checking manuscripts. We introduce RXiv-Maker, a comprehensive system native to Github that simplifies scientific writing through markdown-based authoring with automated LaTeX conversion. It's specifically designed to help produce preprints for curation in arXiv, bioRxiv, and medRxiv. The system lets researchers write in the familiar and lightweight markdown syntax while generating publication-quality documents automatically. RXiv-Maker offers flexible compilation strategies, including cloud-based GitHub Actions, interactive Google Colab notebooks, and reproducible local builds via Docker containerisation, ensuring consistent environments and eliminating dependency conflicts. The framework inherently supports reproducible research by enabling programmatic figure generation using Python libraries and script-based diagramming with Mermaid.js. This self-documenting article, created entirely within the framework, shows how this markdown-centric workflow transforms scientific communication into an efficient, collaborative, and transparent process, empowering researchers to focus on content while upholding rigorous standards of quality and reproducibility.

## Main

<!-- Introduction -->

Today's scientific landscape is marked by the swift sharing of research findings, a trend largely driven by the exponential growth of preprint servers like arXiv, bioRxiv, and medRxiv [@Berg2016; @Abdill2019_biorxiv_growth; @Fraser2021_preprint_growth]. This shift, while accelerating scientific discovery and enhancing research transparency [@Vale2019_preprints; @Tennant2016_academic_publishing], puts a significant new burden on researchers to produce polished manuscripts frequently and efficiently. Traditional tools and workflows for scientific writing, often reliant on proprietary word-processing software, are poorly suited to this new reality. They pose major challenges for version control, collaborative authoring, and ensuring the computational reproducibility of the final document [@Lariviere2014; @da_Silva_2022_challenges]. To tackle these systemic issues, we've developed RXiv-Maker, a GitHub-native framework designed to streamline the entire scientific writing and publication pipeline. The system is built on the principle of using markdown, a simple and intuitive plain-text formatting syntax, as the primary authoring language. This approach fundamentally separates the scientific content from its final presentation, allowing researchers to focus on the substance of their work. The plain-text nature of markdown files makes them ideally suited for management with version control systems like Git. This integration provides an unparalleled level of transparency and traceability for the evolution of a manuscript. Every change, every contribution, and every revision can be precisely tracked, attributed, and, if necessary, reverted. Furthermore, it resolves the convoluted and error-prone process of merging changes from multiple collaborators, a common bottleneck in conventional workflows that often leads to duplicated effort and loss of information.

![](FIGURES/Figure_1.svg)
{#fig:diagram tex_position="t"} **The RXiv-Maker Diagram.** The system integrates Markdown content, YAML metadata, Python scripts, and bibliography files through a processing engine. This engine leverages Docker, GitHub Actions, and LaTeX to produce a publication-ready scientific article, demonstrating a fully automated and reproducible pipeline.

At the heart of the RXiv-Maker philosophy is the pursuit of genuine reproducibility, a fundamental aspect of scientific integrity that extends beyond the experimental data to encompass the entire publication process [@Donoho2010; @Sandve2013_reproducible_research; @Wilson2014_software_carpentry]. Our framework embodies this principle by enabling the programmatic generation of figures and tables, following best practices for computational research [@Scherer2020_reproducibility]. Rather than manually inserting static image files, which obscures the connection between the data and its visualisation, our system promotes the use of scripting languages like Python, with its powerful data visualisation libraries such as Matplotlib [@Hunter2007_matplotlib] and Seaborn [@Waskom2021_seaborn]. Figures are generated directly from the source data and analysis scripts during the manuscript compilation process. This creates an unbreakable, auditable chain from raw data to the final figure. If the underlying data is updated or the analysis is refined, all affected figures are automatically regenerated, ensuring complete consistency and eliminating the possibility of outdated visuals persisting in the manuscript. This dynamic approach transforms figures from mere illustrations into reproducible scientific artefacts. The system also integrates Mermaid.js [@Mermaid2023_documentation], a tool for generating complex diagrams and flowcharts from a simple, text-based syntax. This is particularly valuable for creating clear, version-controlled illustrations of experimental workflows, conceptual models, and algorithms, which are essential for communicating complex ideas in many scientific disciplines. RXiv-Maker, therefore, offers a holistic solution that treats the manuscript not as a static document but as the executable output of the research itself.

RXiv-Maker addresses these requirements through a markdown-centric authoring system that automatically translates familiar markdown syntax into professional LaTeX documents. Built upon the established HenriquesLab bioRxiv template [@HenriquesLab2015_template], the system extends capabilities through automated processing pipelines, integrated figure generation, and flexible deployment strategies. The architecture, detailed in Fig. @fig:diagram and comprehensively illustrated in Sup. Fig. @sfig:workflow, provides automated figure generation for statistical visualisation, integrated Mermaid diagram creation, and robust build automation through containerised environments. The technical details of the figure generation system are described in {@snote:figure-generation}.

<!-- Results -->

![](FIGURES/Figure_2.svg)
{#fig:2 tex_position="t" width=100%} **The growth of preprint submissions on the arXiv server from 1991 to 2025.** The data, sourced from arXiv's public statistics, is plotted using a Python script integrated into our RXiv-Maker pipeline. This demonstrates the system's capacity for reproducible, data-driven figure generation directly within the publication workflow.

Using the RXiv-Maker framework results in a highly efficient and robust workflow for producing professional-quality scientific papers. The system's primary output is a fully typeset PDF document, as seen in the article you're currently reading, which was generated entirely using this process. The markdown source files are automatically converted into a structured LaTeX document, then compiled to produce a PDF with a clean, academic layout, proper pagination, and high-resolution figures. Bibliographic management is handled seamlessly through integration with a standard BibTeX file. The system automatically processes this file to generate correctly formatted in-text citations and a comprehensive bibliography section according to a specified citation style. This automation eliminates the tedious and error-prone task of manually formatting references.

Its utility is further highlighted by the system's flexible deployment options, which cater to a broad range of user preferences and technical environments. We have successfully validated three distinct compilation pathways. Firstly, the cloud-based GitHub Actions workflow offers a fully automated, hands-off experience. Every time code is pushed to the repository, the action is triggered, building a Docker container with all necessary dependencies, compiling the manuscript, and releasing the resulting PDF as a downloadable artefact. This continuous integration pipeline ensures a current, correctly compiled version of the manuscript is always available, serving as a top-notch quality control mechanism for collaborative projects. Secondly, for users who prefer an interactive, web-based environment, the system can be deployed in a Google Colab notebook. This method removes all local software requirements, allowing users to compile the manuscript simply by executing cells within the notebook, making the framework exceptionally accessible to those with limited command-line experience.

Thirdly, for local development, the Docker-based approach provides a perfectly reproducible compilation environment on any host machine. By running a simple command, a user can start the build process within a self-contained Docker container that encapsulates the exact versions of LaTeX and all other required system libraries. This completely eliminates the 'works on my machine' problem, guaranteeing that the output is identical byte-for-byte regardless of the user's local operating system or software configuration [@Boettiger2015_docker_reproducibility]. The integration of programmatic figure generation was also validated, supporting interactive computational environments like Jupyter notebooks [@Jupyter2016_notebook]. Python scripts placed within the designated directory were automatically executed during compilation. These scripts loaded data, performed analyses, and generated visualisations, which were then saved as image files and seamlessly included in the final PDF. Similarly, Mermaid.js diagrams embedded within the markdown source were correctly rendered into SVG images and incorporated into the document. This programmatic integration demonstrates a closed loop of reproducibility, where the final manuscript serves as a verifiable and self-contained record of the research findings and their presentation.

<!-- Discussion and conclusions section -->

Our RXiv-Maker system marks a major step forward in how scientific manuscripts are prepared. By using plain-text markdown and robust open-source tools like Docker, we've created a workflow that boosts efficiency and promotes best practices for reproducibility and collaboration. The main benefit of our framework is that it removes technical complexity from the author's hands. Scientists can focus on the research content and narrative, using simple and widely understood markdown syntax, while the system handles the complex and often frustrating aspects of typesetting, reference management, and dependency control. This approach embraces literate programming principles [@Knuth1984_literate_programming], creating documents that seamlessly blend narrative text with executable code. This is a significant departure from traditional workflows, where researchers often have to act as amateur typesetters, spending hours wrestling with the formatting intricacies of word processors or raw Latex. The integration with Git provides a robust platform for collaborative writing [@Ram2013_git_science; @Perez-Riverol2016_github_bioinformatics], far superior to the chaotic exchange of files via email. It enables transparent attribution, conflict-free merging of contributions, and a complete, auditable history of the manuscript's development.

Within the larger context of the open science movement, RXiv-Maker acts as a practical tool for turning principles into reality. By focusing on automated figure generation and a fully containerised, reproducible build process, the path from raw data to final publication becomes transparent and verifiable. This directly tackles the 'reproducibility crisis' by making it easy to create publications that are not just reports of research, but are themselves computationally reproducible artefacts. This aligns with a growing consensus that the publication itself should be accompanied by the code and data needed to reproduce its findings [@Donoho2010]. Our framework makes this possible by design, treating the manuscript and the code to generate it as two sides of the same coin. While other platforms and tools for scientific writing exist, including sophisticated environments like DL4MicEverywhere [@Hidalgo-Cenalmor2024_DL4MicEverywhere], RXiv-Maker stands out through its simplicity, flexibility, and tight integration with the GitHub ecosystem, which is already the de facto standard for collaborative software development and is increasingly used for scientific projects.

Although Rxiv-Maker has its advantages, we acknowledge certain limitations and areas for future improvement. The current system is mainly designed to produce PDF outputs using Latex. While this is the standard for many scientific disciplines, future versions could support other output formats, such as HTML for web-native articles, potentially leveraging universal document converters like Pandoc [@MacFarlane2022]. Additionally, concerns about reporting quality in preprints [@Kirkham2018_reporting] suggest opportunities for integrating automated quality checks. Additionally, although the system is designed to be accessible, researchers new to Git and markdown may encounter an initial learning curve. To address this, we plan to develop more comprehensive documentation and tutorial materials. Future work will also focus on deeper integration with data analysis environments like Jupyter notebooks, allowing for a more seamless transition from exploratory analysis to manuscript-ready figures. We could also explore integrating automated tools for checking style, grammar, and scientific rigour, further enhancing the system's role as a comprehensive quality control platform. Ultimately, RXiv-Maker is a contribution to a more open, efficient, and reproducible future for scientific communication, providing a powerful and accessible tool for modern researchers.

## Methods

### The RXiv-Maker Processing Pipeline: A Deterministic Automated Workflow

The RXiv-Maker framework implements a deterministic, multi-stage processing pipeline to convert manuscript source files into a compiled Portable Document Format (PDF) document. The entire workflow is orchestrated by a central Makefile that defines a directed acyclic graph (DAG) of dependencies, ensuring a consistent and reproducible order of operations for every build. This Makefile serves as the high-level algorithmic specification for the tool, defining distinct pathways for local and containerized compilation to enhance both accessibility for general users and control for developers.

The primary build process, typically invoked via the `make pdf` target for local compilation, proceeds through five distinct, logically ordered stages:

**Environment Setup** (`setup`): The initial stage prepares the build environment by creating the designated output directory (`output/`) and its necessary subdirectories (e.g., `output/Figures/`). This ensures a clean and predictable workspace for all subsequent build artifacts.

**Programmatic Content Generation** (`figures-conditional`): This stage manages the creation of dynamic content, primarily figures. A key methodological feature is its conditional execution logic. The system inspects the `FIGURES/` directory for source files (e.g., `.py` for Python scripts, `.mmd` for Mermaid diagrams) and checks for the existence of corresponding output files (e.g., `.pdf`, `.png`). The figure generation script (`src/py/commands/generate_figures.py`) is executed only if these output files are absent or if the user explicitly forces regeneration by setting the `FORCE_FIGURES=true` flag. This caching-like behavior represents a critical optimization, balancing the need for reproducibility with computational efficiency by avoiding redundant processing of unchanged assets.

**Core Content Conversion** (`generate`): This is the central conversion step, where the main Python script (`src/py/commands/generate_preprint.py`) is executed. This script parses the primary manuscript markdown file (`MANUSCRIPT/01_MAIN.md`), extracts metadata from the configuration file (`MANUSCRIPT/00_CONFIG.yml`), and synthesizes these inputs into a master LaTeX file (`MANUSCRIPT.tex`) within the output directory.

**Asset Aggregation** (`copy-files`): Following the generation of the primary LaTeX file, this stage gathers all necessary dependencies for compilation into the `output/` directory. This includes LaTeX style files (`.cls`, `.bst`, `.sty`) from `src/tex/style/`, the project's bibliography file (`.bib`), and all generated figures from the `FIGURES/` directory. This aggregation creates a self-contained environment for the final typesetting stage.

**Final Typesetting** (`pdf`): The final stage executes the LaTeX compilation sequence within the `output/` directory. A standard, robust sequence of `pdflatex → bibtex → pdflatex → pdflatex` is used. This multi-pass process ensures that all cross-references (for figures, tables, and equations) and bibliographic citations are correctly resolved, resulting in a polished, publication-ready PDF document. A timeout wrapper is applied to each command to prevent build processes from hanging indefinitely.

For users without a local LaTeX installation, the framework provides an equivalent containerized pathway via the `make easy-build` target, which is an alias for `docker-build`. This target leverages a pre-configured Docker environment to execute the same fundamental pipeline, guaranteeing bit-for-bit reproducibility of the final output across any host system. This dual-pathway design is a core methodological choice that significantly enhances the tool's accessibility and scientific utility.

The Makefile defines several key automation targets that orchestrate the build process: `setup` creates the output directory structure, `figures-conditional` manages programmatic figure generation, `generate` performs the core markdown-to-LaTeX conversion, `copy-files` aggregates all necessary assets, `build` ensures readiness for typesetting, `pdf` executes the LaTeX compilation sequence, and `easy-build` provides a containerized build pathway for users without local LaTeX installations.

### The Markdown-to-LaTeX Conversion Engine

The transformation of the user's markdown manuscript into a structured LaTeX document is not performed by a generic, off-the-shelf converter. Instead, RXiv-Maker employs a custom, multi-pass conversion engine written in Python (`src/py/converters/md2tex.py`). This engine is designed to recognize and process a specific "extended academic Markdown" syntax, which adds essential scientific publishing features to the standard markdown specification. The precise behavior of this engine is formally documented and validated by a comprehensive suite of unit tests, particularly those found in `tests/unit/test_md2tex.py`.

The conversion process can be understood as a pipeline of specialized processing functions, each responsible for a specific syntactic element. This modular architecture allows for robust and maintainable code, where complex transformations are broken down into discrete, testable steps. The key stages of this conversion pipeline include:

**Code Block Protection**: The first pass identifies all fenced code blocks (e.g., ` ```python... ``` `) and replaces them with unique, protected placeholders. This crucial step ensures that the content within these blocks is treated as literal text and is not subjected to any subsequent markdown-to-LaTeX conversion. This preserves code syntax, YAML examples, and other verbatim content without corruption.

**Specialized Element Conversion**: The engine then applies a series of dedicated converters to the remaining text:
- *Citation Processing* (`convert_citations_to_latex`): This function identifies two citation patterns. Single, in-text citations like `@smith2023` are converted to `\cite{smith2023}`. Bracketed, multi-citation groups like `[@smith2023;@jones2022]` are converted to the consolidated LaTeX command `\cite{smith2023,jones2022}`.
- *Figure Processing* (`convert_figures_to_latex`): This processor handles the complex syntax for embedding figures. It recognizes attributes for labels (`#fig:id`), width (`width="0.8"`), and LaTeX placement (`tex_position="!ht"`), translating them into the appropriate `\begin{figure}`, `\includegraphics`, and `\label` commands.
- *Table Processing* (`convert_tables_to_latex`): This handles GitHub-flavored markdown tables, converting them into LaTeX tabular environments. It also supports extended attributes for rotation (`rotate=90`) and column width, wrapping the table in `\rotatebox` or `tabularx` environments as needed.
- *Supplementary Note Processing* (`process_supplementary_notes`): A custom syntax, `{#snote:id} **Title.**`, is used for creating structured supplementary notes. This processor converts these blocks into formatted LaTeX subsections with automatic numbering and labeling, a feature essential for organizing supplementary information.

**Standard Markdown Conversion**: After the specialized elements are handled, the engine applies standard markdown conversion rules for basic formatting, such as transforming `**bold**` to `\textbf{bold}`, `*italic*` to `\textit{italic}`, and headers (`#`, `##`) to LaTeX sectioning commands (`\section`, `\subsection`).

**Placeholder Restoration**: Finally, the protected placeholders for code blocks are restored, inserting the original verbatim content into the appropriate LaTeX environment for syntax highlighting.

This multi-pass, protection-first approach ensures that the extended academic syntax is processed correctly while preventing the accidental conversion of literal content within code blocks. The conversion engine supports several custom syntax extensions including bracketed citations, figure placement attributes, cross-references, rotated tables, language-specific code blocks, and structured supplementary notes.

### Programmatic Content Generation for Reproducible Science

A cornerstone of the RXiv-Maker methodology is its direct support for programmatic content generation, which transforms figures and diagrams from static, manually-created assets into dynamic, reproducible outputs of the scientific analysis itself. This capability is not an add-on but a core, algorithmically-defined part of the build pipeline, ensuring that the final publication is a verifiable and auditable record of the research process.

The mechanism is orchestrated by the `figures` and `figures-conditional` targets in the Makefile. The process follows a clear algorithm:

**Source Identification**: During a build, the system scans the `MANUSCRIPT/FIGURES/` directory for files with recognized executable extensions, primarily `.py` for Python scripts and `.mmd` for Mermaid diagram definitions.

**Conditional Execution**: As described previously, the `figures-conditional` logic determines whether a script needs to be executed. This check for pre-existing output files serves as an effective caching mechanism, significantly speeding up subsequent builds where figure-generating code or data has not changed.

**Interpreter Dispatch**: If execution is required, the system dispatches the source file to the appropriate interpreter:
- *Python Scripts* (`.py`): Files ending in `.py` are executed using the project's configured Python interpreter (`$(PYTHON_CMD)`). These scripts are expected to perform data loading, analysis, and plotting (e.g., using libraries like Matplotlib and Seaborn, as specified in `pyproject.toml`), and save the resulting visualizations as image files (e.g., `.pdf`, `.png`) back into the `FIGURES/` directory.
- *Mermaid Diagrams* (`.mmd`): Files ending in `.mmd` are processed using the Mermaid CLI. This converts the declarative, text-based diagram syntax into vector (`.svg`, `.pdf`) and raster (`.png`) graphics. This allows complex flowcharts and architectural diagrams to be version-controlled and automatically rendered as part of the manuscript.

**Integration**: Once the output files are generated, the markdown-to-LaTeX conversion engine recognizes the corresponding `![Caption](...)` tags in the manuscript's markdown source and embeds the newly created figures into the final document.

This entire process ensures a tight coupling between the data, the code that analyzes it, and the final visual representation in the publication. It elevates the manuscript from a static report to a dynamic, executable artifact, which is a significant step towards achieving the ideals of fully reproducible computational science.

### Environment Encapsulation for Guaranteed Consistency

Reproducibility in computational science is critically dependent on the stability of the software environment. To address this, RXiv-Maker provides a hierarchical strategy for environment management, ensuring that the tool behaves identically regardless of the host system. This is a deliberate methodological choice to eliminate the common "works on my machine" problem.

**Dependency Pinning**: At the most fundamental level, the `pyproject.toml` file explicitly lists all Python dependencies with version specifiers (e.g., `matplotlib>=3.7.0`, `ruff>=0.8.0`). This provides a baseline level of reproducibility for any installation, as it instructs the package manager to use versions known to be compatible with the tool.

**Virtual Environments**: For local development, the Makefile provides a `venv` target to create an isolated Python virtual environment. This prevents conflicts with system-wide packages and ensures that the project's dependencies are self-contained.

**Containerization with Docker**: The highest level of reproducibility is achieved through Docker. The project includes a multi-stage Dockerfile (`src/docker/Dockerfile`) that encapsulates the entire software stack—the specific operating system, LaTeX distribution, Python version, and all system and Python libraries—into a single, portable container image. The `make easy-build` command executes the entire build pipeline within this container, guaranteeing that the process is identical for every user on any platform that supports Docker. This approach provides bit-for-bit reproducibility of the final PDF output.

The sophistication of this approach is further demonstrated by the `.dockerignore` file, which is meticulously crafted to optimize the Docker build process. By excluding build artifacts (`output/`, `build/`), local caches (`__pycache__/`, `.pytest_cache/`), and version control directories (`.git/`), it minimizes the size of the build context sent to the Docker daemon, enhancing the efficiency and speed of the reproducible build process.

Table 3 details the core components of this carefully curated software stack:

| Component/Library | Version/Source | Methodological Role |
|-------------------|----------------|---------------------|
| Python | >=3.9 from `pyproject.toml` | The core scripting and orchestration language for the conversion engine |
| Docker | Docker Engine | Provides a fully encapsulated, reproducible build environment for guaranteed consistency |
| TeX Live | Inferred from Dockerfile | The typesetting system responsible for converting LaTeX source into the final PDF |
| Ruff | v0.8.4 from `.pre-commit-config.yaml` | Provides high-performance, unified code formatting, linting, and import sorting to ensure code quality and consistency |
| Mypy | v1.13.0 from `.pre-commit-config.yaml` | Performs static type checking to reduce runtime errors and improve code reliability |
| Pytest | >=8.0 from `pyproject.toml` | The core framework for executing the unit and integration test suites that validate the tool's functionality |
| Matplotlib | >=3.7.0 from `pyproject.toml` | The primary library for programmatic, data-driven figure generation in Python scripts |
| Mermaid CLI | Inferred from Dockerfile | The command-line tool used to render declarative `.mmd` diagram definitions into graphical formats |

### The Quality Assurance and Validation Framework

In computational science, the software testing framework serves the same role as experimental controls and validation assays in empirical science. It provides the evidence that the computational instrument—the software—is behaving as specified. RXiv-Maker employs a formal, multi-level testing strategy to validate its functionality, which should be described as the validation protocol for the method.

The testing framework, managed via Makefile targets and configured in `pyproject.toml`, is structured into three distinct layers:

**Unit Tests** (`tests/unit/`): This suite forms the foundation of the validation strategy. Each test validates a single, discrete component or conversion rule in isolation. These tests function as precise positive and negative controls. For example, `test_convert_bold_text` in `test_md2tex.py` validates that the `**text**` to `\textbf{text}` conversion works correctly (a positive control). Conversely, tests for markdown inside backticks validate that this same conversion does not occur inside a code block, confirming the specificity of the rule (a negative control). This suite provides granular, verifiable evidence that the core algorithms of the conversion engine are implemented correctly.

**Integration Tests** (`tests/integration/`): This layer validates the successful orchestration of multiple components. Tests like `test_end_to_end_with_citations` verify that the entire pipeline—from parsing a markdown file containing citations and figure references, to generating a LaTeX file with the correct `\cite` and `\ref` commands—functions as a cohesive whole. These tests are analogous to validating a complete experimental protocol from sample preparation to final measurement, ensuring that the interfaces between different modules are working correctly.

**Platform Tests** (`tests/integration/test_platform_integration.py`): This layer validates the tool's functionality in its target deployment environments. These tests verify the behavior of the Docker-based workflows, ensuring that containerized builds produce the expected results across different platforms and architectures.

In addition to this validation suite, the project enforces a proactive quality control pipeline using pre-commit hooks, configured in `.pre-commit-config.yaml`. Before any code change can be committed to the version control system, a series of automated checks are executed. These include code formatting (`ruff-format`), linting (`ruff`), type checking (`mypy`), and even spell-checking of configuration files (`typos`). This automated pipeline serves as a continuous, preventative quality assurance method, ensuring a high standard of code quality, consistency, and correctness throughout the development process.

The project's tooling choices also reflect a deliberate methodology aimed at quality and performance. The configuration explicitly adopts modern, high-performance tools. For instance, the traditional Python-based tools `black`, `isort`, and `flake8` have been replaced by the single, Rust-based tool Ruff, reflecting a move towards faster alternatives while maintaining established tools like `mypy` for type checking. This hybrid approach demonstrates a sophisticated, evidence-based methodology for toolchain construction, prioritizing performance and developer efficiency while maintaining best-in-class functionality.

## Data availability
Arxiv monthly submission data used in this article is available at [https://arxiv.org/stats/monthly_submissions](https://arxiv.org/stats/monthly_submissions). The source code and data for the figures in this article are available at [https://github.com/henriques/rxiv-maker](https://github.com/henriques/rxiv-maker).

## Code availability
The RXiv-Maker computational framework is available at [https://github.com/henriques/rxiv-maker](https://github.com/henriques/rxiv-maker). All source code is under an MIT License.

## Author contributions
Both Bruno M. Saraiva, Guillaume Jacquemet and Ricardo Henriques conceived the project and designed the framework. All authors contributed to writing and reviewing the manuscript.

## Acknowledgements
B.S. and R.H. acknowledge support from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement No. 101001332) (to R.H.) and funding from the European Union through the Horizon Europe program (AI4LIFE project with grant agreement 101057970-AI4LIFE and RT-SuperES project with grant agreement 101099654-RTSuperES to R.H.). Funded by the European Union. However, the views and opinions expressed are those of the authors only and do not necessarily reflect those of the European Union. Neither the European Union nor the granting authority can be held responsible for them. This work was also supported by a European Molecular Biology Organization (EMBO) installation grant (EMBO-2020-IG-4734 to R.H.), a Chan Zuckerberg Initiative Visual Proteomics Grant (vpi-0000000044 with https://doi.org/10.37921/743590vtudfp to R.H.) and a Chan Zuckerberg Initiative Essential Open Source Software for Science (EOSS6-0000000260). This study was supported by the Academy of Finland (no. 338537 to G.J.), the Sigrid Juselius Foundation (to G.J.), the Cancer Society of Finland (Syöpäjärjestöt, to G.J.) and the Solutions for Health strategic funding to Åbo Akademi University (to G.J.). This research was supported by InFLAMES Flagship Program of the Academy of Finland (decision no. 337531).
